{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T19:09:20.698666Z",
     "iopub.status.busy": "2024-11-20T19:09:20.698516Z",
     "iopub.status.idle": "2024-11-20T19:09:23.875612Z",
     "shell.execute_reply": "2024-11-20T19:09:23.874973Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 21:04:44.986818: E external/local_xla/xla/stream_executor/plugin_registry.cc:93] Invalid plugin kind specified: DNN\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "import dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T19:09:23.877390Z",
     "iopub.status.busy": "2024-11-20T19:09:23.877109Z",
     "iopub.status.idle": "2024-11-20T19:09:23.880862Z",
     "shell.execute_reply": "2024-11-20T19:09:23.880297Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 128  # Reduced batch size for multi-task learning\n",
    "IMAGE_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T19:09:23.882850Z",
     "iopub.status.busy": "2024-11-20T19:09:23.882223Z",
     "iopub.status.idle": "2024-11-20T19:09:23.885616Z",
     "shell.execute_reply": "2024-11-20T19:09:23.885009Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset paths\n",
    "dataset_path = os.path.join(os.environ['SEGMENTATION_DATASET_PATH'], 'kaggle_3m')\n",
    "data_csv_path = os.path.join(dataset_path, 'data.csv')\n",
    "\n",
    "# Load patient data\n",
    "patient_data = pd.read_csv(data_csv_path)\n",
    "\n",
    "# Initialize lists to store images and masks for the dataset\n",
    "images = []\n",
    "masks = []\n",
    "patient_ids = []\n",
    "\n",
    "# Loop over each folder (patient case) in the dataset to load images and corresponding masks\n",
    "case_folders = sorted(os.listdir(dataset_path))\n",
    "for folder in case_folders:\n",
    "    folder_path = os.path.join(dataset_path, folder)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue  # Skip non-directory files\n",
    "\n",
    "    # Extract the patient ID from the folder\n",
    "    patient_id = folder  # Folder name represents the patient ID\n",
    "\n",
    "    # List image and mask files in the folder\n",
    "    image_files = sorted([f for f in os.listdir(folder_path) if f.endswith('.tif') and '_mask' not in f])\n",
    "    mask_files = sorted([f for f in os.listdir(folder_path) if f.endswith('_mask.tif')])\n",
    "\n",
    "    for img_file, mask_file in zip(image_files, mask_files):\n",
    "        img_path = os.path.join(folder_path, img_file)\n",
    "        mask_path = os.path.join(folder_path, mask_file)\n",
    "\n",
    "        # Read the image (3-channel TIFF)\n",
    "        img = tiff.imread(img_path)\n",
    "        \n",
    "        # Handle missing channels by repeating the FLAIR sequence if needed\n",
    "        if img.shape[-1] < 3:\n",
    "            img = np.repeat(img[..., :1], 3, axis=-1)  # Repeat FLAIR if missing sequences\n",
    "\n",
    "        # Resize image if necessary (standardize image size)\n",
    "        img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "\n",
    "        # Read the mask (1-channel TIFF)\n",
    "        mask = tiff.imread(mask_path)\n",
    "        mask = cv2.resize(mask, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "        mask = mask.astype(np.uint8)\n",
    "        mask = np.expand_dims(mask, axis=-1)  # Add channel dimension\n",
    "\n",
    "        # Append image and mask\n",
    "        images.append(img)\n",
    "        masks.append(mask)\n",
    "\n",
    "        # Append patient ID\n",
    "        patient_ids.append(patient_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T19:09:23.887221Z",
     "iopub.status.busy": "2024-11-20T19:09:23.886953Z",
     "iopub.status.idle": "2024-11-20T19:09:27.671733Z",
     "shell.execute_reply": "2024-11-20T19:09:27.670980Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert lists to numpy arrays after appending all images and masks\n",
    "images = np.array(images)\n",
    "masks = np.array(masks)\n",
    "patient_ids = np.array(patient_ids)\n",
    "\n",
    "# Normalize the images (optional but helps with training)\n",
    "images = images.astype('float32') / 255.0\n",
    "\n",
    "# Normalize the masks\n",
    "masks = masks.astype('float32') / 255.0\n",
    "\n",
    "# Split the dataset into training, validation, and testing sets (70% training, 15% validation, 15% testing)\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=0.7, random_state=42)\n",
    "train_idx, temp_idx = next(gss.split(images, masks, groups=patient_ids))\n",
    "\n",
    "X_train, X_temp = images[train_idx], images[temp_idx]\n",
    "y_train, y_temp = masks[train_idx], masks[temp_idx]\n",
    "patient_ids_temp = patient_ids[temp_idx]\n",
    "\n",
    "# Split the remaining data into validation and testing sets (50% each of the remaining 30%)\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=0.5, random_state=42)\n",
    "val_idx, test_idx = next(gss.split(X_temp, y_temp, groups=patient_ids_temp))\n",
    "\n",
    "X_val, X_test = X_temp[val_idx], X_temp[test_idx]\n",
    "y_val, y_test = y_temp[val_idx], y_temp[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T19:09:27.673748Z",
     "iopub.status.busy": "2024-11-20T19:09:27.673406Z",
     "iopub.status.idle": "2024-11-20T19:09:27.682506Z",
     "shell.execute_reply": "2024-11-20T19:09:27.681944Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def unet_with_resnet_encoder(input_size=(IMAGE_SIZE, IMAGE_SIZE, 3)):\n",
    "    inputs = Input(input_size)\n",
    "\n",
    "    # Use a pretrained ResNet as the encoder\n",
    "    base_model = ResNet50(include_top=False, weights='imagenet', input_tensor=inputs)\n",
    "    \n",
    "    # Get specific layers from the ResNet model as encoder outputs\n",
    "    c1 = base_model.get_layer('conv1_relu').output\n",
    "    c2 = base_model.get_layer('conv2_block3_out').output\n",
    "    c3 = base_model.get_layer('conv3_block4_out').output\n",
    "    c4 = base_model.get_layer('conv4_block6_out').output\n",
    "\n",
    "    # Bottleneck layer from ResNet\n",
    "    c5 = base_model.get_layer('conv5_block3_out').output\n",
    "\n",
    "    # Decoder with skip connections\n",
    "    u6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
    "\n",
    "    # Final Upsampling Step to Match 128x128\n",
    "    u10 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c9)\n",
    "    c10 = Conv2D(32, (3, 3), activation='relu', padding='same')(u10)\n",
    "    c10 = Conv2D(32, (3, 3), activation='relu', padding='same')(c10)\n",
    "\n",
    "    # Final Layer to Match Mask Dimensions\n",
    "    segmentation_output = Conv2D(1, (1, 1), activation='sigmoid', name='segmentation_output')(c10)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[segmentation_output])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T19:09:27.684011Z",
     "iopub.status.busy": "2024-11-20T19:09:27.683713Z",
     "iopub.status.idle": "2024-11-20T19:09:31.439665Z",
     "shell.execute_reply": "2024-11-20T19:09:31.439028Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create the U-Net segmentation model\n",
    "model = unet_with_resnet_encoder()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T19:09:31.441284Z",
     "iopub.status.busy": "2024-11-20T19:09:31.440965Z",
     "iopub.status.idle": "2024-11-20T20:06:36.378536Z",
     "shell.execute_reply": "2024-11-20T20:06:36.377846Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train the model using the training data\n",
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    epochs=EPOCHS, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    validation_data=(X_val, y_val)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T20:06:36.380336Z",
     "iopub.status.busy": "2024-11-20T20:06:36.380034Z",
     "iopub.status.idle": "2024-11-20T20:06:37.205135Z",
     "shell.execute_reply": "2024-11-20T20:06:37.204442Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save Model Output\n",
    "model.save('segmentation_model.h5')\n",
    "\n",
    "# Save the model history to a file\n",
    "with open('segmentation_training_history.pkl', 'wb') as file:\n",
    "    pickle.dump(history.history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T20:06:37.206985Z",
     "iopub.status.busy": "2024-11-20T20:06:37.206674Z",
     "iopub.status.idle": "2024-11-20T20:06:53.186257Z",
     "shell.execute_reply": "2024-11-20T20:06:53.185637Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training Graph: Accuracy and Loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_results = model.evaluate(X_test, y_test)\n",
    "print(f\"Testing Loss: {test_results[0]}, Testing Accuracy: {test_results[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test the model on PNG or other images\n",
    "def test_image_segmentation_only(model, image_path, image_mask_path):\n",
    "    # Load and preprocess the input image\n",
    "    img = cv2.imread(image_path)\n",
    "    img2 = cv2.imread(image_mask_path)\n",
    "\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Image at path {image_path} could not be loaded.\")\n",
    "    img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE))  # Resize to match training input size\n",
    "    img = img.astype('float32') / 255.0  # Normalize\n",
    "    img = img.reshape(1, IMAGE_SIZE, IMAGE_SIZE, 3)  # Add batch dimension\n",
    "\n",
    "    img2 = cv2.resize(img2, (IMAGE_SIZE, IMAGE_SIZE))  # Resize to match training input size\n",
    "    img2 = img2.astype('float32') / 255.0  # Normalize\n",
    "    img2 = img2.reshape(1, IMAGE_SIZE, IMAGE_SIZE, 3)  # Add batch dimension\n",
    "    \n",
    "    # Predict the segmentation mask\n",
    "    segmentation_pred = model.predict(img)\n",
    "    predicted_mask = (segmentation_pred > 0.5).astype(np.uint8)  # Threshold the output to get binary mask\n",
    "\n",
    "    # Plot the input image, expected mask, and predicted mask\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Input image\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(img[0, :, :, :], cmap='gray')\n",
    "    plt.title('Input Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Expected mask\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(img2[0, :, :, :], cmap='gray')\n",
    "    plt.title('Expected Mask')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Predicted mask\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(predicted_mask[0, :, :, 0], cmap='gray')\n",
    "    plt.title('Predicted Mask')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage for PNG or other images\n",
    "test_image_path = os.path.join(os.environ['SEGMENTATION_DATASET_PATH'], 'kaggle_3m/TCGA_HT_7602_19951103/TCGA_HT_7602_19951103_7.tif')\n",
    "test_image_mask_path = os.path.join(os.environ['SEGMENTATION_DATASET_PATH'], 'kaggle_3m/TCGA_HT_7602_19951103/TCGA_HT_7602_19951103_7_mask.tif')\n",
    "\n",
    "test_image_segmentation_only(model, test_image_path, test_image_mask_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
